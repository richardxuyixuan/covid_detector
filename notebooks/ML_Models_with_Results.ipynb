{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "PbBXWZpcedCS",
    "outputId": "7f6fbdcc-61d8-49a5-b9a1-0c6175e32111"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8b4Vw6bzsIY"
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "DZEku5ImG82G",
    "outputId": "9b69c39a-feb9-4e95-8ff4-9eb7052757ab"
   },
   "outputs": [],
   "source": [
    "# Check the status of gpu\n",
    "!nvidia-smi\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "5cbabffaa8044383818cc582da95da77",
      "632428cf7e8544f0809e6f5a279f6528",
      "40e140df2bf94f5d8104be3018f4fec1",
      "365806da18394f8da3952f4933133e0d",
      "e860d4b51f954391bc0a49c51618d650",
      "27cc28cff00c462f89075124be972564",
      "a32b735183164568bb495665528b153c",
      "b7f4155b54104a4ab31a96d69831c60e"
     ]
    },
    "colab_type": "code",
    "id": "MB8bSF5VG39l",
    "outputId": "ac791d80-6d68-4c13-bf5c-718faf7155d9"
   },
   "outputs": [],
   "source": [
    "# Classification Net\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True) #output in 1x1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8lcbwLOBx5t"
   },
   "outputs": [],
   "source": [
    "class Submodel_1(nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super(Submodel_1, self).__init__()\n",
    "        image_modules = list(model.children())[:-5] #all layer expect last layer\n",
    "        self.modelA = nn.Sequential(*image_modules)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        a = self.modelA(image)\n",
    "        x = F.sigmoid(a)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd3iR64NxLLk"
   },
   "outputs": [],
   "source": [
    "feature_extractor = Submodel_1(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fpu_s-o_wvnZ"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self,num_in_features):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.name = 'classifier'\n",
    "        self.num_in_features = num_in_features\n",
    "        self.fc1 = nn.Linear(self.num_in_features, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 320)\n",
    "        self.fc3 = nn.Linear(320, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_in_features)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        X = F.sigmoid(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "un6AeuFiArDJ"
   },
   "outputs": [],
   "source": [
    "# Load Classifiction data\n",
    "\n",
    "data_path_classify = \"/content/drive/My Drive/Project Files/Final_Dataset/final_dataset/classification_data\"\n",
    "data_path_rndForest = \"/content/drive/My Drive/Project Files/Final_Dataset/final_dataset/classification_data\"\n",
    "\n",
    "\n",
    "transform_classify = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transform_rndForest = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "def ignore_noncovid(path):\n",
    "    if path.find(\"non_covid\") == -1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ignore_nii(path):\n",
    "    if path.find(\"covid_mask_png\") == -1 or path.find(\"outputFile.csv\") != -1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "data_classify = torchvision.datasets.ImageFolder(root=data_path_classify,transform=transform_classify)\n",
    "data_rndForest = torchvision.datasets.ImageFolder(root=data_path_rndForest,transform=transform_rndForest)\n",
    "\n",
    "\n",
    "# Calculate split lengths\n",
    "total_size_classify = len(data_classify)\n",
    "train_size_classify = round(0.7*total_size_classify)\n",
    "valid_size_classify = round(0.15*total_size_classify)\n",
    "test_size_classify = round(0.15*total_size_classify)\n",
    "\n",
    "# Seperate into Train, Val and Test sets\n",
    "random.seed(14)\n",
    "train_set_classify, valid_set_classify, test_set_classify = torch.utils.data.random_split(data_classify, [train_size_classify,valid_size_classify,test_size_classify])\n",
    "\n",
    "\n",
    "def ignore_noncovid(path):\n",
    "    if path.find(\"non_covid\") == -1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ignore_nii(path):\n",
    "    if path.find(\"covid_mask_png\") == -1 or path.find(\"outputFile.csv\") != -1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "# Calculate split lengths\n",
    "total_size_rndForest = len(data_rndForest)\n",
    "train_size_rndForest = round(0.7*total_size_rndForest)\n",
    "test_size_rndForest = round(0.3*total_size_rndForest)\n",
    "\n",
    "train_set_rndForest, test_set_rndForest = torch.utils.data.random_split(data_rndForest, [train_size_rndForest,test_size_rndForest] )\n",
    "\n",
    "\n",
    "# Seperate random Forest Data into images and labels\n",
    "train_set_imgs_rndForest = []\n",
    "train_set_labels_rndForest = []\n",
    "test_set_imgs_rndForest = []\n",
    "test_set_labels_rndForest = []\n",
    "count = 1\n",
    "for data in train_set_rndForest:\n",
    "    clear_output(wait=True)\n",
    "    print(\"Current random Forest split progress:\", count, \"/\",len(data_rndForest))\n",
    "    train_set_imgs_rndForest.append(data[0])\n",
    "    train_set_labels_rndForest.append(data[1])\n",
    "    count += 1\n",
    "\n",
    "for data in test_set_rndForest:\n",
    "    clear_output(wait=True)\n",
    "    print(\"Current random Forest split progress:\", count, \"/\",len(data_rndForest))\n",
    "    test_set_imgs_rndForest.append(data[0])\n",
    "    test_set_labels_rndForest.append(data[1])\n",
    "    count += 1\n",
    "\n",
    "train_set_imgs_rndForest = torch.stack(train_set_imgs_rndForest)\n",
    "train_set_labels_rndForest = np.array(train_set_labels_rndForest)\n",
    "test_set_imgs_rndForest = torch.stack(test_set_imgs_rndForest)\n",
    "test_set_labels_rndForest = np.array(test_set_labels_rndForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gHZAwcO4R3A"
   },
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "# 1-Random Forest (From Scikit Learn)\n",
    "baseLine_rndForest = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# Train randomForest\n",
    "with torch.no_grad():\n",
    "    trainFeature = resnet18(train_set_imgs_rndForest)\n",
    "    testFeature = resnet18(test_set_imgs_rndForest)\n",
    "\n",
    "baseLine_rndForest.fit(trainFeature, train_set_labels_rndForest)\n",
    "\n",
    "# Test randomForest Accuracy\n",
    "pred = baseLine_rndForest.predict(testFeature)\n",
    "correct = (pred == test_set_labels_rndForest).sum()\n",
    "total = testFeature.shape[0]\n",
    "print(\"Random Forest Accuracy is: \", correct/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJ5_4E2uCGMw"
   },
   "outputs": [],
   "source": [
    "def train_net(transfer_net,net, train_data,val_data, batch_size=64, learning_rate=0.01, num_epochs=30, gpu = True):\n",
    "    ########################################################################\n",
    "    # Fixed PyTorch random seed for reproducible result\n",
    "    torch.manual_seed(1000)\n",
    "    ########################################################################\n",
    "    # Define the Loss function and optimizer\n",
    "    # The loss function will be Binary Cross Entropy (BCE). In this case we\n",
    "    # will use the BCEWithLogitsLoss which takes unnormalized output from\n",
    "    # the neural network and scalar label.\n",
    "    # Optimizer will be SGD with Momentum.\n",
    "    learned_parameters = []\n",
    "    for param in transfer_net.parameters():\n",
    "        learned_parameters.append(param)\n",
    "    for param in net.parameters():\n",
    "        learned_parameters.append(param)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(learned_parameters, lr=learning_rate)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data,batch_size=batch_size,shuffle=True)\n",
    "    ########################################################################\n",
    "    # Set up some numpy arrays to store the training/test loss/erruracy\n",
    "    train_err = np.zeros(num_epochs)\n",
    "    train_loss = np.zeros(num_epochs)\n",
    "    val_err = np.zeros(num_epochs)\n",
    "    val_loss = np.zeros(num_epochs)\n",
    "    ########################################################################\n",
    "    # Train the network\n",
    "    # Loop over the data iterator and sample a new batch of training data\n",
    "    # Get the output from the network, and optimize our loss function.\n",
    "    start_time = time.time()\n",
    "    if gpu:\n",
    "        transfer_net = transfer_net.cuda()\n",
    "        net = net.cuda()\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        total_train_loss = 0.0\n",
    "        total_train_err = 0.0\n",
    "        total_epoch = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # Get the inputs\n",
    "            inputs, labels = data\n",
    "            if gpu:\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass, backward pass, and optimize\n",
    "            outputs = net(transfer_net(inputs))\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Calculate the statistics\n",
    "            corr = (outputs > 0.0).squeeze().long() != labels\n",
    "            total_train_err += int(corr.sum())\n",
    "            total_train_loss += loss.item()\n",
    "            total_epoch += len(labels)\n",
    "        train_err[epoch] = float(total_train_err) / total_epoch\n",
    "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
    "        val_err[epoch], val_loss[epoch] = evaluate(transfer_net,net, val_loader, criterion,gpu)\n",
    "        print((\"Epoch {}: Train err: {}, Train loss: {} |\"+\n",
    "               \"Validation err: {}, Validation loss: {}\").format(\n",
    "                   epoch + 1,\n",
    "                   train_err[epoch],\n",
    "                   train_loss[epoch],\n",
    "                   val_err[epoch],\n",
    "                   val_loss[epoch]))\n",
    "        # Save the current model (checkpoint) to a file\n",
    "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "    print('Finished Training')\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
    "    # Write the train/test loss/err into CSV file for plotting later\n",
    "    epochs = np.arange(1, num_epochs + 1)\n",
    "    np.savetxt(\"{}_train_err.csv\".format(model_path), train_err)\n",
    "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
    "    np.savetxt(\"{}_val_err.csv\".format(model_path), val_err)\n",
    "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)\n",
    "\n",
    "\n",
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path\n",
    "\n",
    "def evaluate(transfer_net, net, loader, criterion, gpu):\n",
    "    \"\"\" Evaluate the network on the validation set.\n",
    "\n",
    "     Args:\n",
    "         net: PyTorch neural network object\n",
    "         loader: PyTorch data loader for the validation set\n",
    "         criterion: The loss function\n",
    "     Returns:\n",
    "         err: A scalar for the avg classification error over the validation set\n",
    "         loss: A scalar for the average loss function over the validation set\n",
    "     \"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_err = 0.0\n",
    "    total_epoch = 0\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        inputs, labels = data\n",
    "        if gpu:\n",
    "          inputs = inputs.cuda()\n",
    "          labels = labels.cuda()\n",
    "        outputs = net(transfer_net(inputs))\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        corr = (outputs > 0.0).squeeze().long() != labels\n",
    "        total_err += int(corr.sum())\n",
    "        total_loss += loss.item()\n",
    "        total_epoch += len(labels)\n",
    "    err = float(total_err) / total_epoch\n",
    "    loss = float(total_loss) / (i + 1)\n",
    "    return err, loss\n",
    "\n",
    "###############################################################################\n",
    "# Training Curve\n",
    "def plot_training_curve(path):\n",
    "    \"\"\" Plots the training curve for a model run, given the csv files\n",
    "    containing the train/validation error/loss.\n",
    "\n",
    "    Args:\n",
    "        path: The base path of the csv files produced during training\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n",
    "    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n",
    "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
    "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
    "    plt.title(\"Train vs Validation Error\")\n",
    "    n = len(train_err) # number of epochs\n",
    "    plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    plt.title(\"Train vs Validation Loss\")\n",
    "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "112be0abcd9843b8aaec7aff80a3162b",
      "352a9aba9f4849eeb18d555a89e98e94",
      "935b57bee3274d7b9c9378644a6bfbc5",
      "6b459f9dba4844c99c25749cba159bf6",
      "c56fa534314a4112a9e78f06f5cee3aa",
      "276dfda4ae6f400ead19b3bfd13b9833",
      "7fe38852a64b489388bce83894b6b67e",
      "77633d2a701f461795976974824a092a"
     ]
    },
    "colab_type": "code",
    "id": "u4spne0RwdHv",
    "outputId": "8fc518a7-a77e-4206-ad60-894324cb55f9"
   },
   "outputs": [],
   "source": [
    "# Initialize handcrafted classifier and train the transfer learning + ANN network\n",
    "classifier = Classifier(1000)\n",
    "train_net(resnet18,classifier,train_set_classify,valid_set_classify,batch_size=64,learning_rate=0.001,num_epochs=15)\n",
    "model_path = get_model_name(\"classifier\", batch_size=64, learning_rate=0.001, epoch=14)\n",
    "plot_training_curve(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Ez6I7O-t_64F",
    "outputId": "5a9ea097-a84e-40df-eb97-873241d1fd33"
   },
   "outputs": [],
   "source": [
    "# Report the Test Accuracy\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "gpu = True\n",
    "test_err, test_acc = evaluate(resnet18,classifier,torch.utils.data.DataLoader(test_set_classify,batch_size=64),criterion,gpu)\n",
    "print('Test Accuracy is',1-test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUMsBFmzix3b"
   },
   "outputs": [],
   "source": [
    "data_path_img_autoEncoder = \"/content/drive/My Drive/Project Files/Final_Dataset/final_dataset/classification_data\"\n",
    "data_path_mask_autoEncoder = \"/content/drive/My Drive/Project Files/Final_Dataset/final_dataset/covid_mask\"\n",
    "\n",
    "transform_autoEncoder = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "transform_feature_extractor = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def ignore_noncovid(path):\n",
    "    if path.find(\"non_covid\") == -1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ignore_nii(path):\n",
    "    if path.find(\"covid_mask_png\") == -1 or path.find(\"outputFile.csv\") != -1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "data_img_feature_extractor = torchvision.datasets.ImageFolder(root=data_path_img_autoEncoder,transform=transform_feature_extractor,is_valid_file=ignore_noncovid)\n",
    "data_img_autoEncoder = torchvision.datasets.ImageFolder(root=data_path_img_autoEncoder,transform=transform_autoEncoder,is_valid_file=ignore_noncovid)\n",
    "data_mask_autoEncoder = torchvision.datasets.ImageFolder(root=data_path_mask_autoEncoder,transform=transform_autoEncoder,is_valid_file=ignore_nii)\n",
    "\n",
    "print('the number of images match=',len(data_img_autoEncoder) == len(data_mask_autoEncoder))\n",
    "\n",
    "# Build (image,Mask) pairs\n",
    "data_autoEncoder = []\n",
    "for i in range(len(data_img_autoEncoder)):\n",
    "\n",
    "  data_autoEncoder.append((data_img_autoEncoder[i][0],data_mask_autoEncoder[i][0],data_img_feature_extractor[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foLFlQvR1tro"
   },
   "outputs": [],
   "source": [
    "# Visualize Images\n",
    "for i in range(0,len(data_autoEncoder)):\n",
    "  plt.figure()\n",
    "  plt.imshow(data_autoEncoder[i][0].reshape(224,224))\n",
    "  plt.figure()\n",
    "  #print(torch.transpose(mask_data[i][0],0,2)[220][340])\n",
    "  plt.imshow(data_autoEncoder[i][1].reshape(224,224))\n",
    "  if i > 4:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4AHsmoe1xcE"
   },
   "outputs": [],
   "source": [
    "# Training:Validation:Test = 0.7:0.15:0.15\n",
    "random.seed(14)\n",
    "random.shuffle(data_autoEncoder)\n",
    "\n",
    "train_index = int(len(data_autoEncoder) * 0.7)\n",
    "val_index = int(len(data_autoEncoder) * 0.85)\n",
    "\n",
    "training_data = data_autoEncoder[:train_index]\n",
    "valid_data = data_autoEncoder[train_index:val_index]\n",
    "test_data = data_autoEncoder[val_index:]\n",
    "print(\"# Train Set: \" + str(len(training_data)))\n",
    "print(\"# Test Set: \" + str(len(test_data)))\n",
    "print(\"# Val Set: \" + str(len(valid_data)))\n",
    "\n",
    "def initialize_loader(train_dataset,valid_dataset,train_batch_size=64, val_batch_size=64):\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=val_batch_size,shuffle=True)\n",
    "    return train_loader, valid_loader\n",
    "train_d = torch.utils.data.DataLoader(training_data, batch_size=64, num_workers=1)\n",
    "valid_d = torch.utils.data.DataLoader(valid_data, batch_size=64, num_workers=1)\n",
    "test_d = torch.utils.data.DataLoader(test_data, batch_size=64, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uroSJdCy15Id"
   },
   "outputs": [],
   "source": [
    "# 2-Convolutional Autoencoder (Hard-coded)\n",
    "class baseline_autoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(baseline_autoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential( # like the Composition layer you built\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 7),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 2, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Unet\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_filters, num_colours, num_in_channels, kernel=3):\n",
    "        super(UNet, self).__init__()\n",
    "        # Calculate padding\n",
    "        padding = kernel // 2\n",
    "        # Model\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(num_in_channels, num_filters, kernel_size=kernel, padding=padding),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(num_filters, num_filters*2, kernel_size=kernel, padding=padding),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(num_filters*2),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(num_filters*2 + 64, num_filters*2, kernel_size=kernel, padding=padding),\n",
    "            nn.BatchNorm2d(num_filters*2),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(num_filters*2+num_filters*2, num_filters, kernel_size=kernel, padding=padding),\n",
    "            nn.Upsample(scale_factor=2),            \n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(num_filters+num_filters, num_colours, kernel_size=kernel, padding=padding),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.BatchNorm2d(num_colours),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(num_colours+num_in_channels, num_colours, kernel_size=kernel, padding=padding),\n",
    "        )  \n",
    "\n",
    "\n",
    "    def forward(self, x, feature_tensor): \n",
    "        self.o1 = self.layer1(x)\n",
    "        self.o2 = self.layer2(self.o1)\n",
    "        self.o3 = self.layer3(torch.cat((self.o2,feature_tensor),1))\n",
    "        self.o4 = self.layer4(torch.cat((self.o3, self.o2),1))\n",
    "        self.o5 = self.layer5(torch.cat((self.o4, self.o1),1))\n",
    "        self.o6 = self.layer6(torch.cat((self.o5,x),1))\n",
    "        return self.o6\n",
    "\n",
    "\n",
    "def iou_pytorch(outputs, labels):\n",
    "    \n",
    "    SMOOTH = 1e-6\n",
    "    # print('raw',outputs.shape)\n",
    "    outputs = torch.argmax(outputs, 1)\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    # print('output=',outputs)\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zero if both are 0\n",
    "    # print('intersection=',intersection)\n",
    "    # print('union=',union)\n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # smooth our devision to avoid 0/0\n",
    "    # print('iou=',iou)\n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  \n",
    "    \n",
    "    return thresholded.mean() \n",
    "\n",
    "\n",
    "def convert_to_binary(masks, thres=0.5):\n",
    "    binary_masks = ((masks[:, 0, :, :] ==  128) & (masks[:, 1, :, :] == 0) & (masks[:, 2, :, :] == 0)) + 0.\n",
    "    return binary_masks.long()\n",
    "\n",
    "def run_validation_step(args, epoch, model, loader, feature_extractor):\n",
    "\n",
    "    model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "\n",
    "    losses = []\n",
    "    ious = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks,raw_input) in enumerate(loader):\n",
    "            if args.gpu:\n",
    "                images = images.cuda()\n",
    "                masks = masks.cuda()\n",
    "                raw_input = raw_input.cuda()\n",
    "            feature = feature_extractor(raw_input)\n",
    "            output = model(images.float(),feature)\n",
    "            # pred_seg_masks = output[\"out\"]\n",
    "\n",
    "            output_predictions = output.argmax(0)\n",
    "            loss = compute_loss(output, masks.squeeze(1).long())\n",
    "            iou = iou_pytorch(output, masks.squeeze(1).long())\n",
    "            losses.append(loss.data.item())\n",
    "            ious.append(iou.data.item())\n",
    "\n",
    "        val_loss = np.mean(losses)\n",
    "        val_iou = np.mean(ious)\n",
    "    \n",
    "    return val_loss, val_iou\n",
    "\n",
    "def train(args, model, feature_extractor):\n",
    "    \n",
    "    # Set the maximum number of threads to prevent crash\n",
    "    torch.set_num_threads(5)\n",
    "    # Numpy random seed\n",
    "    np.random.seed(args.seed)\n",
    "    \n",
    "    # Save directory\n",
    "    # Create the outputs folder if not created already\n",
    "    save_dir = \"outputs/\" + args.experiment_name\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    # Adam Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learn_rate)\n",
    "\n",
    "    train_loader, valid_loader = initialize_loader(training_data,valid_data,args.train_batch_size,args.val_batch_size)\n",
    "\n",
    "    print(\"Beginning training ...\")\n",
    "    if args.gpu: \n",
    "        model.cuda()\n",
    "\n",
    "    start = time.time()\n",
    "    trn_losses = []\n",
    "    val_losses = []\n",
    "    val_ious = []\n",
    "    best_iou = 0.0\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        # Train the Model\n",
    "        model.train() # Change model to 'train' mode\n",
    "        start_tr = time.time()\n",
    "        \n",
    "        losses = []\n",
    "        for i, (images, masks, raw_input) in enumerate(train_loader):\n",
    "\n",
    "            if args.gpu:\n",
    "                images = images.cuda()\n",
    "                masks = masks.cuda()\n",
    "                raw_input = raw_input.cuda()\n",
    "            features = feature_extractor(raw_input)\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images.float(),features)\n",
    "            # pred_seg_masks = output[\"out\"])\n",
    "            # _, pred_labels = torch.max(output, 1, keepdim=True)\n",
    "            loss = compute_loss(output, masks.squeeze(1).long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.data.item())\n",
    "\n",
    "\n",
    "        # plot training images\n",
    "        trn_loss = np.mean(losses)\n",
    "        trn_losses.append(trn_loss)\n",
    "        time_elapsed = time.time() - start_tr\n",
    "        print('Epoch [%d/%d], Loss: %.4f, Time (s): %d' % (\n",
    "                epoch+1, args.epochs, trn_loss, time_elapsed))\n",
    "\n",
    "        # Evaluate the model\n",
    "        start_val = time.time()\n",
    "        val_loss, val_iou = run_validation_step(args, \n",
    "                                                epoch, \n",
    "                                                model,\n",
    "                                                valid_loader, feature_extractor)\n",
    "\n",
    "        if val_iou > best_iou:\n",
    "            best_iou = val_iou\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, args.checkpoint_name + '-best.ckpt'))\n",
    "\n",
    "        time_elapsed = time.time() - start_val\n",
    "        print('Epoch [%d/%d], Loss: %.4f, mIOU: %.4f, Validation time (s): %d' % (\n",
    "                epoch+1, args.epochs, val_loss, val_iou, time_elapsed))\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_ious.append(val_iou)\n",
    "\n",
    "    # Plot training curve\n",
    "    plt.figure()\n",
    "    # plt.plot(trn_losses, \"ro-\", label=\"Train\")\n",
    "    # plt.plot(val_losses, \"go-\", label=\"Validation\")\n",
    "    plt.plot(trn_losses,  label=\"Train\")\n",
    "    plt.plot(val_losses,  label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(save_dir+\"/training_curve.png\")\n",
    "\n",
    "    # Plot validation iou curve\n",
    "    plt.figure()\n",
    "    plt.plot(val_ious, \"ro-\", label=\"mIOU\")\n",
    "    plt.legend()\n",
    "    plt.title(\"mIOU\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(save_dir+\"/val_iou_curve.png\")\n",
    "\n",
    "    print('Saving model...')\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, args.checkpoint_name + '-{}-last.ckpt'.format(args.epochs)))\n",
    "\n",
    "    print('Best model achieves mIOU: %.4f' % best_iou)\n",
    "\n",
    "\n",
    "def compute_loss(pred, gt):\n",
    "    loss = F.cross_entropy(pred, gt,weight=torch.Tensor([0.1,4.15]).cuda())\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nAbv9Lk2AFy"
   },
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "# Baseline Hyperparameters\n",
    "args_baseline = AttrDict()\n",
    "args_dict = {\n",
    "              'gpu':True, \n",
    "              'checkpoint_name':\"baseline_segmentation\", \n",
    "              'learn_rate':0.1, \n",
    "              'train_batch_size':64, \n",
    "              'val_batch_size': 256, \n",
    "              'epochs':10, \n",
    "              'seed':0,\n",
    "              'experiment_name': 'baseline_segmentation',\n",
    "}\n",
    "args_baseline.update(args_dict)\n",
    "\n",
    "# Unet Hyperparameters\n",
    "args_unet = AttrDict()\n",
    "\n",
    "args_dict = {\n",
    "              'gpu':True, \n",
    "              'checkpoint_name':\"unet_segmentation\", \n",
    "              'learn_rate':0.01, \n",
    "              'train_batch_size':128, \n",
    "              'val_batch_size': 256, \n",
    "              'epochs':20, \n",
    "              'seed':14,\n",
    "              'experiment_name': 'unet_segmentation',\n",
    "}\n",
    "args_unet.update(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Xz4x3Gz2J9X"
   },
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "baseline_segmentation = baseline_autoEncoder()\n",
    "train(args_baseline,baseline_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8hZRRbd2O9_"
   },
   "outputs": [],
   "source": [
    "# Train Unet\n",
    "unet = UNet(10,2,1)\n",
    "feature_extractor = feature_extractor.cuda()\n",
    "train(args_unet,unet,feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fKUPgPq2Vgr"
   },
   "outputs": [],
   "source": [
    "# Visualize a few predictions in test set\n",
    "feature_extractor = feature_extractor.cuda()\n",
    "for (imgs,masks,raw_input) in test_d:\n",
    "  pred = unet(imgs.float().cuda(),feature_extractor(raw_input.cuda()))\n",
    "  msk = masks\n",
    "  raw = raw_input\n",
    "  pred = torch.argmax(pred, 1)\n",
    "  break\n",
    "for i in range(len(pred)):\n",
    "  fig = plt.figure(figsize=(15,4.5))\n",
    "  plt.title('prediction vs. ground truth vs. input image')\n",
    "  ax = fig.add_subplot(1,3,1)\n",
    "  plt.imshow(pred[i+10].cpu().detach().numpy())\n",
    "  ax = fig.add_subplot(1,3,2)\n",
    "  plt.imshow(msk[i+10].cpu().detach().numpy().squeeze(0))\n",
    "  ax = fig.add_subplot(1,3,3)\n",
    "  plt.imshow(np.transpose(raw[i+10],(1,2,0)))\n",
    "  i += 1\n",
    "  if i > 10:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Workspace.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "112be0abcd9843b8aaec7aff80a3162b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_935b57bee3274d7b9c9378644a6bfbc5",
       "IPY_MODEL_6b459f9dba4844c99c25749cba159bf6"
      ],
      "layout": "IPY_MODEL_352a9aba9f4849eeb18d555a89e98e94"
     }
    },
    "276dfda4ae6f400ead19b3bfd13b9833": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27cc28cff00c462f89075124be972564": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "352a9aba9f4849eeb18d555a89e98e94": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "365806da18394f8da3952f4933133e0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7f4155b54104a4ab31a96d69831c60e",
      "placeholder": "​",
      "style": "IPY_MODEL_a32b735183164568bb495665528b153c",
      "value": " 44.7M/44.7M [02:52&lt;00:00, 271kB/s]"
     }
    },
    "40e140df2bf94f5d8104be3018f4fec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27cc28cff00c462f89075124be972564",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e860d4b51f954391bc0a49c51618d650",
      "value": 46827520
     }
    },
    "5cbabffaa8044383818cc582da95da77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40e140df2bf94f5d8104be3018f4fec1",
       "IPY_MODEL_365806da18394f8da3952f4933133e0d"
      ],
      "layout": "IPY_MODEL_632428cf7e8544f0809e6f5a279f6528"
     }
    },
    "632428cf7e8544f0809e6f5a279f6528": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b459f9dba4844c99c25749cba159bf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77633d2a701f461795976974824a092a",
      "placeholder": "​",
      "style": "IPY_MODEL_7fe38852a64b489388bce83894b6b67e",
      "value": " 44.7M/44.7M [00:11&lt;00:00, 4.14MB/s]"
     }
    },
    "77633d2a701f461795976974824a092a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fe38852a64b489388bce83894b6b67e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "935b57bee3274d7b9c9378644a6bfbc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_276dfda4ae6f400ead19b3bfd13b9833",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c56fa534314a4112a9e78f06f5cee3aa",
      "value": 46827520
     }
    },
    "a32b735183164568bb495665528b153c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7f4155b54104a4ab31a96d69831c60e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c56fa534314a4112a9e78f06f5cee3aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e860d4b51f954391bc0a49c51618d650": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
